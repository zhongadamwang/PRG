---
name: plan-estimateeffort
description: Provides effort estimates for development tasks using multiple estimation methods including PERT, complexity analysis, and risk factors. Generates estimates with confidence levels and rationale for structured project planning.
license: MIT
---

# Plan.EstimateEffort Skill

## Intent
Generate accurate effort estimates for development tasks using multiple estimation methodologies (PERT, complexity analysis, historical analogies) with confidence intervals and detailed rationale to support project planning and resource allocation decisions.

## Inputs
- **Source**: `projects/[project-name]/artifacts/Analysis/task-breakdown.json` (generated by plan-derivetasks skill)
- **Optional**: Historical project data or team velocity metrics from previous projects
- **Format**: Structured task data with descriptions, acceptance criteria, and dependencies

## Outputs

**Files Generated:**
- `projects/[project-name]/artifacts/Analysis/effort-estimates.json` - Structured estimation data for programmatic use
- `projects/[project-name]/artifacts/Analysis/effort-estimates.md` - Human-readable estimation report with rationale
- `projects/[project-name]/artifacts/Analysis/estimation-confidence.md` - Confidence analysis and calibration info

### JSON Structure (`effort-estimates.json`)
```json
{
  "project_id": "string",
  "generated_at": "ISO_timestamp",
  "estimation_methods": ["PERT", "complexity-points", "analogies"],
  "total_project_estimate": {
    "optimistic_days": 0.0,
    "most_likely_days": 0.0,
    "pessimistic_days": 0.0,
    "expected_days": 0.0,
    "standard_deviation": 0.0,
    "confidence_interval_80": {"min": 0.0, "max": 0.0},
    "confidence_interval_95": {"min": 0.0, "max": 0.0}
  },
  "estimation_factors": {
    "team_experience": "novice|intermediate|expert",
    "technology_familiarity": "new|familiar|expert", 
    "project_complexity": "simple|moderate|complex|very_complex",
    "requirements_clarity": "clear|moderate|unclear",
    "integration_complexity": "simple|moderate|complex"
  },
  "task_estimates": [
    {
      "task_id": "string",
      "title": "string",
      "category": "string",
      "pert_estimate": {
        "optimistic_days": 0.0,
        "most_likely_days": 0.0,
        "pessimistic_days": 0.0,
        "expected_days": 0.0,
        "variance": 0.0
      },
      "complexity_factors": {
        "technical_complexity": "1-5_scale",
        "business_logic_complexity": "1-5_scale",
        "integration_complexity": "1-5_scale",
        "uncertainty_factor": "1-5_scale",
        "total_story_points": 0
      },
      "risk_factors": [
        {
          "risk": "string",
          "impact": "low|medium|high",
          "probability": "low|medium|high",
          "effort_multiplier": 0.0
        }
      ],
      "historical_analogies": [
        {
          "similar_task": "string",
          "similarity_score": "0.0-1.0",
          "actual_effort": 0.0,
          "adjusted_estimate": 0.0
        }
      ],
      "confidence_level": "0-100_percent",
      "rationale": "string",
      "estimation_notes": ["string_list"]
    }
  ],
  "summary_statistics": {
    "total_tasks": 0,
    "tasks_by_category": {
      "development": {"count": 0, "total_effort": 0.0},
      "testing": {"count": 0, "total_effort": 0.0},
      "design": {"count": 0, "total_effort": 0.0},
      "documentation": {"count": 0, "total_effort": 0.0}
    },
    "critical_path_effort": 0.0,
    "parallel_work_potential": 0.0
  }
}
```

### Markdown Structure (`effort-estimates.md`)
```markdown
# Project Effort Estimates

## Executive Summary
- **Total Expected Effort**: [expected_days] days
- **Confidence Range (80%)**: [min_days] - [max_days] days  
- **Critical Path**: [critical_path_days] days
- **Estimation Approach**: PERT + Complexity + Risk Analysis

## Estimation Context
- **Team Experience**: [experience_level]
- **Technology Stack**: [familiarity_level]
- **Project Complexity**: [complexity_level]
- **Requirements Certainty**: [clarity_level]

## Task Estimates Detail
[Individual task breakdown with rationale]

## Risk Factors & Mitigation
[Risk analysis affecting estimates]

## Estimation Methodology
[Documentation of estimation approach]

## Confidence Analysis
[Discussion of estimate reliability]
```

## Core Estimation Methods

### 1. PERT (Program Evaluation and Review Technique)
Apply three-point estimation for each task:
- **Optimistic (O)**: Best case scenario, everything goes well
- **Most Likely (M)**: Realistic estimate based on normal conditions  
- **Pessimistic (P)**: Worst case with reasonable risks materialized

**Formulas:**
- Expected Time: `E = (O + 4M + P) / 6`
- Variance: `V = ((P - O) / 6)²`
- Standard Deviation: `SD = √V`

### 2. Complexity Point Estimation
Assess each task on multiple complexity dimensions (1-5 scale):
- **Technical Complexity**: Algorithm complexity, technical challenges
- **Business Logic**: Domain complexity, rule complexity
- **Integration Complexity**: API dependencies, data flow complexity  
- **Uncertainty Factor**: Requirements clarity, unknowns

**Calculation:**
```
Story Points = (Technical + Business + Integration + Uncertainty) / 4
Base Effort = Story Points * Team Velocity (days per point)
```

### 3. Historical Analogy Method
Compare tasks to historical similar work:
- Identify analogous tasks from previous projects
- Calculate similarity scores (0.0-1.0) based on:
  - Technology similarity
  - Complexity similarity  
  - Team experience similarity
- Adjust historical effort based on differences

### 4. Risk Factor Adjustment
Apply effort multipliers based on identified risks:
```
Risk Multiplier = 1.0 + (Risk_Impact * Risk_Probability * Base_Multiplier)

Common Risk Factors:
- New technology: 1.2-1.5x multiplier
- External dependencies: 1.1-1.3x multiplier  
- Unclear requirements: 1.3-1.8x multiplier
- Integration complexity: 1.1-1.4x multiplier
- Team inexperience: 1.2-2.0x multiplier
```

## Estimation Algorithm

### Step 1: Task Analysis
For each task from task-breakdown.json:
1. Analyze task description and acceptance criteria
2. Identify complexity factors and assign scores
3. Identify potential risks and their impacts
4. Search for historical analogies

### Step 2: Base Estimation
1. Generate PERT estimates (O, M, P) for each task
2. Calculate complexity-based story points
3. Apply analogy-based adjustments

### Step 3: Risk Adjustment
1. Apply risk multipliers to base estimates
2. Aggregate risk impacts across dependent tasks
3. Calculate confidence levels based on uncertainty

### Step 4: Project-Level Aggregation
1. Sum individual task estimates
2. Calculate critical path effort
3. Identify opportunities for parallel work
4. Generate confidence intervals for total project

### Step 5: Calibration & Validation
1. Cross-check estimates against industry benchmarks
2. Validate against team historical performance
3. Flag estimates outside reasonable bounds
4. Document assumptions and limitation

## Confidence Level Calculation

```
Confidence = 100 - (Uncertainty_Score * Risk_Score)

Where:
- Uncertainty_Score (0-50): Based on requirements clarity and task definition
- Risk_Score (0-50): Based on identified risks and their probabilities

Confidence Levels:
- 90-100%: High confidence, well-defined tasks, low risk
- 70-89%: Medium confidence, some unknowns or moderate risks  
- 50-69%: Low confidence, significant uncertainties or high risks
- <50%: Very low confidence, requires further analysis
```

## Quality Assurance

### Estimation Validation Rules
1. **Sanity Checks**:
   - No task < 0.25 days (too granular) or > 10 days (needs breakdown)
   - PERT pessimistic should be 1.5-3x optimistic
   - Total variance should align with project complexity

2. **Consistency Checks**:
   - Similar complexity tasks have similar estimates
   - Dependencies reflect in estimate sequences
   - Category totals align with typical project distributions

3. **Calibration Monitoring**:
   - Track actual vs. estimated effort over time
   - Maintain team velocity and complexity factor calibration
   - Update risk multipliers based on historical outcomes

## Usage Guidelines

### When to Use This Skill
- After tasks have been derived from requirements (plan-derivetasks)
- Before project scheduling and resource planning
- When multiple estimation methods needed for accuracy
- For projects requiring confidence intervals and risk assessment

### Best Practices
1. **Input Quality**: Ensure task descriptions are detailed and acceptance criteria clear
2. **Team Calibration**: Adjust complexity factors based on team experience and technology familiarity
3. **Historical Data**: Leverage previous project data when available for analogy-based estimation
4. **Risk Assessment**: Include both technical and non-technical risks in analysis
5. **Iterative Refinement**: Update estimates as project progresses and uncertainties resolve

### Common Applications
- Project proposal effort estimation
- Sprint planning and capacity allocation  
- Risk analysis and contingency planning
- Resource planning and team sizing
- Client estimation and contract scoping

## Expert Patterns

### Technology-Specific Multipliers
```
Web Development:
- Frontend (React/Vue): Base multiplier 1.0
- Backend API: Base multiplier 1.1  
- Database design: Base multiplier 1.2
- Authentication/Security: Base multiplier 1.3

Mobile Development:
- Native iOS/Android: Base multiplier 1.2
- Cross-platform: Base multiplier 1.4
- Device integration: Base multiplier 1.5

Data/ML Projects:  
- Data pipeline: Base multiplier 1.3
- Model development: Base multiplier 1.5
- MLOps deployment: Base multiplier 1.7
```

### Team Experience Adjustments
```
Expert Team (5+ years): 0.7-0.8x multiplier
Experienced Team (3-5 years): 0.9-1.0x multiplier  
Intermediate Team (1-3 years): 1.1-1.3x multiplier
Novice Team (<1 year): 1.5-2.0x multiplier
```

This skill provides comprehensive effort estimation that balances analytical rigor with practical applicability, supporting data-driven project planning decisions.